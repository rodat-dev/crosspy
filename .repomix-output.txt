This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-03-15T13:30:19.113Z

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
src/
  ai_chat/
    main.py
.gitignore
build.bat
build.sh
README.md
requirements.txt
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="src/ai_chat/main.py">
from rich import print
from rich.prompt import Prompt
from rich.panel import Panel
from openai import OpenAI
def main():
    api_key = Prompt.ask("[bold green]Enter your [bold blue]OpenAI API key[/bold blue][/bold green]")
    client = OpenAI(api_key=api_key)
    print(Panel.fit(
        "Welcome to the AI Chat!",
        title="[bold green]AI Chat[/bold green]",
        subtitle="[bold blue]Ask anything you want[/bold blue]",
        border_style="green",
    ))
    messages = [
        {"role": "system", "content": "You are a helpful assistant."},
    ]
    while True:
        user_input = Prompt.ask("[bold blue]You[/bold blue]")
        if user_input.lower() in ["exit", "quit"]:
            print("[bold green]AI:[/bold green] Goodbye!")
            break
        messages.append({"role": "user", "content": user_input})
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            max_tokens=100,
            temperature=0.7,
        )
        ai_response = response.choices[0].message.content.strip()
        messages.append({"role": "assistant", "content": ai_response})
        print(Panel.fit(
            f"[bold green]AI:[/bold green] {ai_response}",
            title="[bold green]AI[/bold green]",
            border_style="green",
        ))
if __name__ == "__main__":
    main()
</file>

<file path=".gitignore">
.cursorrules
.venv
dist
</file>

<file path="build.bat">
@echo off
rem Windows build script for development testing

echo Detecting architecture...
if "%PROCESSOR_ARCHITECTURE%"=="AMD64" (
    echo Building for Windows x64...
    set ARCH_FLAG=--msvc=latest
) else (
    echo Building for Windows x86...
    set ARCH_FLAG=--msvc=latest
)

echo Installing dependencies...
pip install -r requirements.txt
pip install nuitka ordered-set zstandard

echo Building application...
python -m nuitka --standalone %ARCH_FLAG% --windows-icon-from-ico=icon.ico ^
    --follow-imports --disable-ccache ^
    --output-dir=dist src/ai_chat/main.py

echo Build complete! Check the 'dist' directory for your compiled application.
</file>

<file path="build.sh">
#!/bin/bash
# Local build script for development testing
# Determine OS and architecture
OS="$(uname -s)"
ARCH="$(uname -m)"
echo "Detected OS: $OS, Architecture: $ARCH"
# Install dependencies
pip install -r requirements.txt
pip install nuitka ordered-set zstandard
if [[ "$OS" == "Darwin" ]]; then  # macOS
    if [[ "$ARCH" == "arm64" ]]; then
        echo "Building for macOS ARM64..."
        python -m nuitka --standalone --macos-create-app-bundle --macos-target-arch=arm64 \
            --follow-imports --disable-ccache \
            --output-dir=dist src/ai_chat/main.py
    else
        echo "Building for macOS x86_64..."
        python -m nuitka --standalone --macos-create-app-bundle --macos-target-arch=x86_64 \
            --follow-imports --disable-ccache \
            --output-dir=dist src/ai_chat/main.py
    fi
    # Create DMG (optional)
    hdiutil create -volname "AI Chat" -srcfolder dist/main.app -ov -format UDZO dist/AIChat.dmg
elif [[ "$OS" == "Linux" ]]; then  # Linux
    echo "Building for Linux..."
    python -m nuitka --standalone \
        --follow-imports --disable-ccache \
        --output-dir=dist src/ai_chat/main.py
elif [[ "$OS" == "MINGW"* || "$OS" == "MSYS"* ]]; then  # Windows
    echo "Building for Windows..."
    if [[ "$ARCH" == "x86_64" ]]; then
        python -m nuitka --standalone --msvc=latest --windows-icon-from-ico=icon.ico \
            --follow-imports --disable-ccache \
            --output-dir=dist src/ai_chat/main.py
    else
        python -m nuitka --standalone --msvc=latest --windows-icon-from-ico=icon.ico \
            --follow-imports --disable-ccache \
            --output-dir=dist src/ai_chat/main.py
    fi
else
    echo "Unsupported OS: $OS"
    exit 1
fi
echo "Build complete! Check the 'dist' directory for your compiled application."
</file>

<file path="README.md">
# AI Chat Application

A cross-platform Python application for interacting with OpenAI's GPT models.

## Requirements

- Python 3.11 or higher
- pip package manager

## Building from Source

This repository contains everything needed to build the application for multiple platforms:

### Local Development Builds

#### macOS and Linux
```bash
# Make the script executable
chmod +x build.sh

# Run the build script
./build.sh
```

#### Windows
```cmd
# Run the build script
build.bat
```

### Using GitHub Actions

The repository contains GitHub Actions workflows that automatically build the application for:
- macOS ARM64 (Apple Silicon)
- macOS x86_64 (Intel)
- Windows 64-bit
- Windows 32-bit

To trigger a build manually:
1. Go to the "Actions" tab in GitHub
2. Select the "Build AI Chat App" workflow
3. Click "Run workflow"
4. The compiled binaries will be available as artifacts after the build is complete

## Platform-Specific Notes

### macOS

The macOS build creates a `.app` bundle that can be installed by dragging it to your Applications folder. It also creates a DMG file for easy distribution.

### Windows

The Windows build creates a standalone executable with all dependencies included.

## Custom Builds

If you need to customize the build process, you can modify the Nuitka parameters in the build scripts or GitHub Actions workflow.
</file>

<file path="requirements.txt">
annotated-types==0.7.0
anyio==4.8.0
certifi==2025.1.31
distro==1.9.0
h11==0.14.0
httpcore==1.0.7
httpx==0.28.1
idna==3.10
jiter==0.9.0
markdown-it-py==3.0.0
mdurl==0.1.2
openai==1.66.3
pydantic==2.10.6
pydantic_core==2.27.2
Pygments==2.19.1
rich==13.9.4
sniffio==1.3.1
tqdm==4.67.1
typing_extensions==4.12.2
</file>

</files>
